{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick Data Analysis\n",
    "\n",
    "Did not use Time Series analysis because next order pick time is not dependent on previous order pick time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background/Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Results Summary\n",
    "\n",
    "The MAE (median absolute error) of the baseline (using just the mean pick seconds to predict) is 95 seconds     \n",
    "\n",
    "Using 2 features only: total lines per order (a measure of order complexity) and if the order is picked in the last hour of the day:\n",
    "- the 2 degree polynomial model MAE is 33 seconds on both in sample and out of sample data\n",
    "- this is a 65% improvement in prediction accuracy using the model instead of the mean to predict pick time\n",
    "\n",
    "Using only 1 feature: total lines produced nearly identical results (with .01 of previous results) I conclude that the is_hr_18 feature is not needed for modeling.      \n",
    "\n",
    "Prediction accuracy of pick seconds per order can be improved by 65% just using the total lines on the order as a feature in a 2 degree polynomial feature model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire\n",
    "import prepare\n",
    "import wrangle_pick\n",
    "import summarize\n",
    "import explore\n",
    "import model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, explained_variance_score\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# This is to make sure matplotlib doesn't throw the following error:\n",
    "# The next line fixes \"TypeError: float() argument must be a string or a number, not 'Timestamp' matplotlib\"\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "\n",
    "explore.set_plotting_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pickdf.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PH_PICKEDB', 'PH_PICKSTA', 'PH_PICKEND', 'PH_TOTALLI', 'PH_TOTALBO'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test= wrangle_pick.wrangle_pick_data()\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# found that Xy function was changing original train, validate, test\n",
    "# try creating copies first so that original are uneffected\n",
    "X_train = train.copy()\n",
    "X_validate = validate.copy()\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploration of train shows 2% of orders are more than 1 box, dropping these to reduce noise for mvp\n",
    "X_train_exp, X_train, X_validate, X_test, y_train, y_validate, y_test = wrangle_pick.createXy(X_train, X_validate, X_test)\n",
    "\n",
    "X_train_exp.shape, X_train.shape, X_validate.shape, X_test.shape, y_train.shape, y_validate.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, X_train_exp.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df for explore where orders with more than 1 box are included\n",
    "exp = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df for time series exploration includes orders with more than 1 box\n",
    "ts = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-TS index Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep explore dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = exp[['total_lines', 'total_boxes', 'pick_seconds', 'operator', 'hour', 'day', 'day_name', \n",
    "            'week', 'month', 'year', 'sec_per_box', 'lines_per_box', 'sec_per_line' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export this dataframe for exploring in Tableau\n",
    "exp1.to_csv('exp1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = pd.read_csv('exp1.csv', index_col=0)\n",
    "exp1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check for observations where pick_seconds is 0\n",
    "\n",
    "- none where seconds is 0, 1, or 2 only 3 records where time is 4 seconds\n",
    "\n",
    "Checking to make sure orders have a minimum time greater than 2 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1[exp1.pick_seconds==3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create visualizations\n",
    "\n",
    "**DEFINITIONS**     \n",
    "- each observation is 1 order to fulfill\n",
    "- the number of lines is the number of (unique?) items to put in the box\n",
    "- each order is a minimum of 1 box, though more boxes may be needed\n",
    "    - check if lines are higher on multiple box orders\n",
    "    - compare mean pick times for multiple box orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1.groupby(['total_boxes']).total_lines.agg(['mean', 'median', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the avg lines for orders with more than 1 box?\n",
    "avg2plusbox = exp1[exp1.total_boxes >1].total_lines.agg(['mean', 'count'])\n",
    "# what is the avg line for orders with 1 box?\n",
    "avg1box = exp1[exp1.total_boxes == 1].total_lines.agg(['mean', 'count'])\n",
    "# what is the population average?\n",
    "popavg = exp1.total_lines.agg(['mean', 'count'])\n",
    "print('average total_lines=', popavg)\n",
    "print('average lines for orders with 1 box=', avg1box)\n",
    "print('average lines for orders with 2 or more boxes=', avg2plusbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- there are, relatively, very few orders with more than 1 box (only 2K out of 96K)\n",
    "- might want to drop observations with more than 1 box for MVP model to reduce noise\n",
    "- due to the imbalance of data the overall average and 1 box average are nearly the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Test 1\n",
    "\n",
    "Is the variance between the average number of lines for the orders with more than 1 box significantly different from the population average?\n",
    "\n",
    "Ho: The difference is not significant     \n",
    "Ha: There is a significant difference between the average number of lines      \n",
    "alpha = .05 (meaning there 95% confidence variation is not due to random chance)     \n",
    "\n",
    "The p is less than alpha so the null hypothesis (Ho) is rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use one sample t-test\n",
    "over1box = exp1[exp1.total_boxes >1].total_lines\n",
    "popmean = exp1.total_lines.mean()\n",
    "t, p = explore.ttest_1samp(over1box, popmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1.groupby(['total_boxes']).pick_seconds.agg(['mean', 'median', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the avg pick time for orders with more than 1 box?\n",
    "pickavg2plusbox = exp1[exp1.total_boxes >1].pick_seconds.agg(['mean', 'median', 'count'])\n",
    "# what is the avg pick time for orders with 1 box?\n",
    "pickavg1box = exp1[exp1.total_boxes == 1].pick_seconds.agg(['mean', 'median', 'count'])\n",
    "# what is the average pick time?\n",
    "pickpopavg = exp1.pick_seconds.agg(['mean', 'median', 'count'])\n",
    "print('average total_lines=')\n",
    "print(pickpopavg)\n",
    "print('average lines for orders with 1 box=')\n",
    "print(pickavg1box)\n",
    "print('average lines for orders with 2 or more boxes=')\n",
    "print(pickavg2plusbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Test 2\n",
    "\n",
    "Is the variance between the average pick seconds for the orders with more than 1 box significantly different from the population average?\n",
    "\n",
    "Ho: The difference is not significant     \n",
    "Ha: There is a significant difference between the average pick seconds for orders with more than 1 box      \n",
    "alpha = .05 (meaning there 95% confidence variation is not due to random chance)     \n",
    "\n",
    "The p is less than alpha so the null hypothesis (Ho) is rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use one sample t-test\n",
    "pover1box = exp1[exp1.total_boxes >1].pick_seconds\n",
    "ppopmean = exp1.pick_seconds.mean()\n",
    "t, p = explore.ttest_1samp(pover1box, ppopmean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore variation in pick seconds\n",
    "\n",
    "- each row is an order, so the pick seconds is per order\n",
    "- maximum outlier is 8000 seconds, or about 2.2 hours\n",
    "- plot have y axis limit set to 2000 or about 30 min to reduce the visual impact of the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Tableau\n",
    "exp1.to_csv('explore_all_boxes.csv')\n",
    "X_train_exp.to_csv('exp_only_1box.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### does the pick seconds vary by hour of day?\n",
    "- operating hours start at 7a and end at 6p\n",
    "- lots of outliers\n",
    "- not much variation until last hour of day\n",
    "- pattern is the same with only 1 box orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=exp1, y='pick_seconds', x='hour')\n",
    "plt.title('pick seconds by hour')\n",
    "plt.ylim(0, 2000)\n",
    "plt.show()\n",
    "# note: y axis is limited to 2000 seconds, or about 30 min to reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=X_train_exp, y='pick_seconds', x='hour')\n",
    "plt.title('pick seconds by hour with only 1 box orders')\n",
    "plt.ylim(0, 500)\n",
    "plt.show()\n",
    "# note: y axis is limited to 2000 seconds, or about 30 min to reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### does the pick seconds vary by day of week?\n",
    "- not much on average, but there seem to be a lot of outliers?\n",
    "- pattern is the same with only 1 box orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "sns.boxplot(data=exp1, y='pick_seconds', x='day_name', order=order)\n",
    "plt.title('pick seconds by day of week')\n",
    "plt.ylim(0, 2000)\n",
    "plt.show()\n",
    "# note: y axis is limited to 2000 seconds, or about 30 min to reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "sns.boxplot(data=X_train_exp, y='pick_seconds', x='day_name', order=order)\n",
    "plt.title('pick seconds by day of week only orders with 1 box')\n",
    "plt.ylim(0, 2000)\n",
    "plt.show()\n",
    "# note: y axis is limited to 2000 seconds, or about 30 min to reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### does the pick seconds vary by day of month?\n",
    "- no real pattern of variation by day of month\n",
    "- same with only 1 box orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=exp1, y='pick_seconds', x='day')\n",
    "plt.title('pick seconds by day of month')\n",
    "plt.ylim(0, 2000)\n",
    "plt.show()\n",
    "# note: y axis is limited to 2000 seconds, or about 30 min to reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=X_train_exp, y='pick_seconds', x='day')\n",
    "plt.title('pick seconds by day of month only orders with 1 box')\n",
    "plt.ylim(0, 2000)\n",
    "plt.show()\n",
    "# note: y axis is limited to 2000 seconds, or about 30 min to reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### does do the pick seconds vary by week of year?\n",
    "- some variation possibly due to complexity of order variation?\n",
    "- not enough of a consistent patter to use as model feature\n",
    "- minimal change with only 1 box orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=exp1, y='pick_seconds', x='week')\n",
    "plt.title('pick seconds by week of year')\n",
    "plt.ylim(0, 2000)\n",
    "plt.show()\n",
    "# note: y axis is limited to 2000 seconds, or about 30 min to reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=X_train_exp, y='pick_seconds', x='week')\n",
    "plt.title('pick seconds by week of year only orders with 1 box')\n",
    "plt.ylim(0, 2000)\n",
    "plt.show()\n",
    "# note: y axis is limited to 2000 seconds, or about 30 min to reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### does the pick seconds vary by month of year?\n",
    "- no variation by month\n",
    "- no change with only 1 box orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=exp1, y='pick_seconds', x='month')\n",
    "plt.title('pick seconds by month of year')\n",
    "plt.ylim(0, 2000)\n",
    "plt.show()\n",
    "# note: y axis is limited to 2000 seconds, or about 30 min to reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=X_train_exp, y='pick_seconds', x='month')\n",
    "plt.title('pick seconds by month of year only orders with 1 box')\n",
    "plt.ylim(0, 2000)\n",
    "plt.show()\n",
    "# note: y axis is limited to 2000 seconds, or about 30 min to reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### does the pick seconds vary by year?\n",
    "- not really any variation by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=exp1, y='pick_seconds', x='year')\n",
    "plt.title('pick seconds by year')\n",
    "plt.ylim(0, 2000)\n",
    "plt.show()\n",
    "# note: y axis is limited to 2000 seconds, or about 30 min to reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=X_train_exp, y='pick_seconds', x='year')\n",
    "plt.title('pick seconds by year only orders with 1 box')\n",
    "plt.ylim(0, 2000)\n",
    "plt.show()\n",
    "# note: y axis is limited to 2000 seconds, or about 30 min to reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore variation in total lines\n",
    "\n",
    "This impacts the complexity of the orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### does the total lines vary by hour of day?\n",
    "- operating hours start at 7a and end at 6p\n",
    "- lines are lightest at beginning and end of day with a spike around 5p\n",
    "- note the y axis has been limited to 50 lines to reduce the visual impact of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=exp1, y='total_lines', x='hour')\n",
    "plt.ylim(0, 50)\n",
    "plt.show()\n",
    "# note: y axis is limited to 50 lines reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### does the total lines vary by day of week?\n",
    "- not much on average, but there seem to be a lot of outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "sns.boxplot(data=exp1, y='total_lines', x='day_name', order=order)\n",
    "plt.ylim(0, 50)\n",
    "plt.show()\n",
    "# note: y axis is limited to 50 lines reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### does the total lines vary by day of month?\n",
    "- some variation on average by day of month\n",
    "- first 4 days of month tend to be higher\n",
    "- final days of month tend to be lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=exp1, y='total_lines', x='day')\n",
    "plt.ylim(0, 50)\n",
    "plt.show()\n",
    "# note: y axis is limited to 50 lines reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### does the total lines vary by week of year?\n",
    "- Christmas and Thanksgiving weeks are lighter\n",
    "- weeks at beginning of months are generally larger and weeks at end of month fewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=exp1, y='total_lines', x='week')\n",
    "plt.ylim(0, 50)\n",
    "plt.show()\n",
    "# note: y axis is limited to 50 lines reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### does the total lines vary by month of year?\n",
    "- not really any variation by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=exp1, y='total_lines', x='month')\n",
    "plt.ylim(0, 50)\n",
    "plt.show()\n",
    "# note: y axis is limited to 50 lines reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### does the total lines vary by year?\n",
    "- not really any variation by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=exp1, y='total_lines', x='year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### does the total boxes vary by day of week?\n",
    "- only outliers?\n",
    "- typically the boxes per pick is 1 so this may not be a good feature for analysis\n",
    "- might need to treat values <1 as anomalies and remove from dataset?\n",
    "    - yes, picks with 0 boxes returned 7 observations that are anomalies and will be removed for this round\n",
    "- visualization also shows total_boxes over 20 as anomalies\n",
    "- note y axis is limited to 10 boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "sns.boxplot(data=exp1, y='total_boxes', x='day_name', order=order)\n",
    "plt.ylim(0, 10)\n",
    "plt.show()\n",
    "# note: y axis is limited to 10 boxes reduce visual impact of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "\n",
    "- prep for model??\n",
    "    - drop observations where there is more than 1 box to reduce noise\n",
    "    - these represent 2% of train dataset\n",
    "    - YES will drop then create X, y sets then make an X scaled and keep not scaled as well\n",
    "    \n",
    "- need to create feature booleen columns\n",
    "    - only 1 found in data = is hour 18\n",
    "    \n",
    "- initial model features total_lines, sec_per_line (scale both of these), and is_hour_18 (boolean)\n",
    "    - all other columns dropped\n",
    "    \n",
    "    \n",
    "Decided to use Median Absolute Error to evaluate.     \n",
    "\"The median_absolute_error is particularly interesting because it is robust to outliers. The loss is calculated by taking the median of all absolute differences between the target and the prediction.\"\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#median-absolute-error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Baseline\n",
    "\n",
    "- Baseline is the mean pick_seconds per order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = round(y_train.pick_seconds.mean(), 2)\n",
    "print(f'The average pick seconds per order is', baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict bps_pred_mean (baseline predicted mean)\n",
    "bps_pred_mean = y_train['pick_seconds'].mean()\n",
    "y_train['bps_pred_mean'] = bps_pred_mean\n",
    "y_validate['bps_pred_mean'] = bps_pred_mean\n",
    "y_test['bps_pred_mean'] = bps_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Absolute Error (MAE) recommended for non-normally distributed data\n",
    "# may not matter giving the law of large numbers?\n",
    "\n",
    "base_med_abs_train = median_absolute_error(y_train.pick_seconds, y_train.bps_pred_mean)\n",
    "print(\"MAE using baseline Mean\\nTrain/In-Sample: \", round(base_med_abs_train, 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evsb = explained_variance_score(y_train.pick_seconds, y_train.bps_pred_mean)\n",
    "print('Explained Variance = ', round(evsb,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "- create and scale features\n",
    "- drop unnecessary columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_validate_scaled, X_test_scaled = wrangle_pick.model_preprocess1(X_train, X_validate, X_test)\n",
    "X_train_scaled.shape, X_validate_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Round Models\n",
    "\n",
    "Features = total lines, picked in 18th hour of day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (OLS) Model\n",
    "\n",
    "- Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lm = LinearRegression(normalize=True)\n",
    "# no change in result if normalize is True or False\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm.fit(X_train_scaled, y_train.pick_seconds)\n",
    "\n",
    "# predict train\n",
    "y_train['ps_pred_lm'] = lm.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_med_abs_train = median_absolute_error(y_train.pick_seconds, y_train.ps_pred_lm)\n",
    "print(\"MAE using Mean\\nTrain/In-Sample: \", round(lm_med_abs_train, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweedie Regressor (GLM) Model\n",
    "\n",
    "- Generalized Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "glm = TweedieRegressor(power=0, alpha=0)\n",
    "# tried power (1, 2, 3) and alpha .1 and 1; 0 and 0 provide best result\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "glm.fit(X_train_scaled, y_train.pick_seconds)\n",
    "\n",
    "# predict train\n",
    "y_train['ps_pred_glm'] = glm.predict(X_train_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.ps_pred_glm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_med_abs_train = median_absolute_error(y_train.pick_seconds, y_train.ps_pred_glm)\n",
    "print(\"MAE using Mean\\nTrain/In-Sample: \", round(glm_med_abs_train, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Feature Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree=2)\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree2 = pf.fit_transform(X_train_scaled)\n",
    "# tried 3, 4, 8 degrees but not much different in performance and 2 is less likely to overfit\n",
    "    \n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree2 = pf.transform(X_validate_scaled)\n",
    "X_test_degree2 = pf.transform(X_test_scaled)\n",
    "\n",
    "# create the model object\n",
    "lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm2.fit(X_train_degree2, y_train.pick_seconds)\n",
    "\n",
    "# predict train\n",
    "y_train['ps_pred_pflm2'] = lm2.predict(X_train_degree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pflm2_med_abs_train = median_absolute_error(y_train.pick_seconds, y_train.ps_pred_pflm2)\n",
    "print(\"MAE using Mean\\nTrain/In-Sample: \", round(pflm2_med_abs_train, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate\n",
    "\n",
    "Given that the OLS and GLM model performance is identical I will run the OLS and Polynomial Feature models on the validate dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regreesion predict validate\n",
    "y_validate['ps_pred_lm'] = lm.predict(X_validate_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_med_abs_val = median_absolute_error(y_validate.pick_seconds, y_validate.ps_pred_lm)\n",
    "print(\"MAE using Mean\\nTrain/Out-of-Sample: \", round(lm_med_abs_val, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Features predict validate\n",
    "# predict validate\n",
    "y_validate['ps_pred_pflm2'] = lm2.predict(X_validate_degree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pflm2_med_abs_val = median_absolute_error(y_validate.pick_seconds, y_validate.ps_pred_pflm2)\n",
    "print(\"MAE using Mean\\nTrain/Out-of-Sample: \", round(pflm2_med_abs_val, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "I will run the Polynomial Feature models on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Features predict validate\n",
    "# predict test\n",
    "y_test['ps_pred_pflm2'] = lm2.predict(X_test_degree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pflm2_med_abs_test = median_absolute_error(y_test.pick_seconds, y_test.ps_pred_pflm2)\n",
    "print(\"MAE using Mean\\nTrain/Out-of-Sample: \", round(pflm2_med_abs_test, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evsr1 = explained_variance_score(y_validate.pick_seconds, y_validate.ps_pred_pflm2)\n",
    "print('Explained Variance = ', round(evsr1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Round Follow up Models\n",
    "\n",
    "Is the result the same with only 1 feature?      \n",
    "\n",
    "Will use OLS and Polynomial models to test this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy X_train_scaled and drop column is_hr_18\n",
    "X_train_scaled2 = X_train_scaled.copy()\n",
    "X_train_scaled2 = X_train_scaled2.drop(columns='is_hr_18')\n",
    "X_validate_scaled2 = X_validate_scaled.copy()\n",
    "X_validate_scaled2 = X_validate_scaled2.drop(columns='is_hr_18')\n",
    "X_test_scaled2 = X_test_scaled.copy()\n",
    "X_test_scaled2 = X_test_scaled2.drop(columns='is_hr_18')\n",
    "X_train_scaled2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (OLS) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lm2 = LinearRegression(normalize=True)\n",
    "# no change in result if normalize is True or False\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm2.fit(X_train_scaled2, y_train.pick_seconds)\n",
    "\n",
    "# predict train\n",
    "y_train['ps_pred_lm2'] = lm2.predict(X_train_scaled2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_med_abs_train2 = median_absolute_error(y_train.pick_seconds, y_train.ps_pred_lm2)\n",
    "print(\"MAE using Mean\\nTrain/In-Sample: \", round(lm_med_abs_train2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Feature Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf2 = PolynomialFeatures(degree=2)\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree22 = pf2.fit_transform(X_train_scaled2)\n",
    "# tried 3, 4, 8 degrees but not much different in performance and 2 is less likely to overfit\n",
    "    \n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree22 = pf2.transform(X_validate_scaled2)\n",
    "X_test_degree22 = pf2.transform(X_test_scaled2)\n",
    "\n",
    "# create the model object\n",
    "lm22 = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm22.fit(X_train_degree22, y_train.pick_seconds)\n",
    "\n",
    "# predict train\n",
    "y_train['ps_pred_pflm22'] = lm22.predict(X_train_degree22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pflm22_med_abs_train2 = median_absolute_error(y_train.pick_seconds, y_train.ps_pred_pflm22)\n",
    "print(\"MAE using Mean\\nTrain/In-Sample: \", round(pflm22_med_abs_train2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regreesion predict validate\n",
    "y_validate['ps_pred_lm2'] = lm2.predict(X_validate_scaled2)\n",
    "lm_med_abs_val2 = median_absolute_error(y_validate.pick_seconds, y_validate.ps_pred_lm2)\n",
    "print(\"MAE using Mean\\nTrain/Out-of-Sample: \", round(lm_med_abs_val2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Features predict validate\n",
    "# predict validate\n",
    "y_validate['ps_pred_pflm22'] = lm22.predict(X_validate_degree22)\n",
    "pflm22_med_abs_val2 = median_absolute_error(y_validate.pick_seconds, y_validate.ps_pred_pflm22)\n",
    "print(\"MAE using Mean\\nTrain/Out-of-Sample: \", round(pflm22_med_abs_val2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Features predict validate\n",
    "# predict test\n",
    "y_test['ps_pred_pflm22'] = lm22.predict(X_test_degree22)\n",
    "pflm22_med_abs_test2 = median_absolute_error(y_test.pick_seconds, y_test.ps_pred_pflm22)\n",
    "print(\"MAE using Mean\\nTrain/Out-of-Sample: \", round(pflm22_med_abs_test2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.metrics.explained_variance_score\n",
    "\n",
    "evsr1f = explained_variance_score(y_test.pick_seconds, y_test.ps_pred_pflm22)\n",
    "print('Explained Variance = ', round(evsr1f,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Round Results Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAE (median absolute error) of the baseline (using just the mean pick seconds to predict) is 95 seconds     \n",
    "\n",
    "Using 2 features only: total lines per order (a measure of order complexity) and if the order is picked in the last hour of the day:\n",
    "- the 2 degree polynomial model MAE is 33 seconds on both in sample and out of sample data\n",
    "- this is a 65% improvement in prediction accuracy using the model instead of the mean to predict pick time\n",
    "\n",
    "Using only 1 feature: total lines produced nearly identical results (with .01 of previous results) I conclude that the is_hr_18 feature is not needed for modeling.      \n",
    "\n",
    "Prediction accuracy of pick seconds per order can be improved by 65% just using the total lines on the order as a feature in a 2 degree polynomial feature model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore by Operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create aggregate df by operator\n",
    "operdf = train.groupby(['operator'])['total_lines', 'total_boxes',  'pick_seconds', 'start', 'end', 'hour'].\\\n",
    "                        agg({'total_lines': ['sum'], 'total_boxes' : ['sum', 'count'], 'pick_seconds': ['sum'], \\\n",
    "                             'start': ['min'], 'end': ['max'], 'hour': ['min', 'max']})\n",
    "\n",
    "# use this to unstack the column names\n",
    "operdf.columns = [' '.join(col).strip() for col in operdf.columns.values]\n",
    "\n",
    "# use this for multiple aggregation\n",
    "# # df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
    "\n",
    "#web_crossover.groupby(['name', 'lesson'])[['sub_lesson']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operdf = operdf.rename(columns={'total_lines sum': 'total_lines', 'total_boxes sum': 'total_boxes', \\\n",
    "                                'total_boxes count': 'total_orders', 'pick_seconds sum': 'total_pick_sec', \\\n",
    "                                'start min': 'first_day', 'end max': 'last_day', 'hour min': 'shift_start_hour', \\\n",
    "                                'hour max': 'shift_end_hour'\n",
    "                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operdf['tenure_days'] = operdf.last_day - operdf.first_day\n",
    "operdf['shift_length'] = operdf.shift_end_hour - operdf.shift_start_hour\n",
    "operdf.tenure_days = operdf.tenure_days.dt.days\n",
    "#operdf.tenure_days = operdf.tenure_days.replace(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin by tenure and visualize?\n",
    "operdf['avg_sec_per_order'] = operdf.total_pick_sec/operdf.total_orders\n",
    "operdf['avg_line_per_order'] = operdf.total_lines/operdf.total_orders\n",
    "operdf['avg_box_per_order'] = operdf.total_boxes/operdf.total_orders\n",
    "operdf['avg_orders_day'] = operdf.total_orders/operdf.tenure_days\n",
    "operdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can't have less than 1 day of tenure really\n",
    "operdf.tenure_days == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the dataframe in case this doesn't work\n",
    "operdf2 = operdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find where the tenure days is 0 and drop those observations\n",
    "index = operdf2[operdf2.tenure_days == 0].index\n",
    "operdf2.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bins based on tenure, anyone not in a bin assign to under 90 days bin\n",
    "operdf2['tenure_bin'] = pd.cut(operdf2.tenure_days, bins=[0, 90, 365, 730, 1095], labels=[.25, 1, 2, 3])\n",
    "operdf2.tenure_bin = operdf2.tenure_bin.fillna(.25)\n",
    "operdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write operdf2 to csv for Tableau\n",
    "operdf2.to_csv('operator.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the average pick seconds per order vary by operator tenure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "sns.boxplot(data=operdf2, y='avg_sec_per_order', x='tenure_bin')\n",
    "plt.title('Average seconds per order by Tenure bin')\n",
    "plt.xlabel('Tenure in years')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the order complexity (lines per order) vary by operator tenure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "sns.boxplot(data=operdf2, y='avg_line_per_order', x='tenure_bin')\n",
    "plt.title('Average lines per order by Tenure bin')\n",
    "plt.xlabel('Tenure in years')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does average orders per day vary by tenure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "sns.boxplot(data=operdf2, y='avg_orders_day', x='tenure_bin')\n",
    "plt.title('Average orders per day by Tenure bin')\n",
    "plt.xlabel('Tenure in years')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the average boxes per order vary by operator tenure?\n",
    "\n",
    "- note: this is removed for modeling, as only orders with 1 box are being used in model currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "sns.boxplot(data=operdf2, y='avg_box_per_order', x='tenure_bin')\n",
    "plt.title('Average boxes per order by Tenure bin')\n",
    "plt.xlabel('Tenure in years')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create is_PartTime feature\n",
    "operdf2['is_part_time'] = np.where(operdf2.shift_length <= 6, 1, 0)\n",
    "operdf2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the average pick seconds vary by part time vs full time operator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "sns.boxplot(data=operdf2, y='avg_sec_per_order', x='is_part_time')\n",
    "plt.title('Average pick seconds per order by shift length, FT=0, PT=1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the % of FT/PT by tenure bin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_tenure = pd.crosstab(operdf2.is_part_time, operdf2.tenure_bin, normalize=True, margins=True)\n",
    "shift_tenure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does average orders per day vary by shift length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "sns.boxplot(data=operdf2, y='avg_orders_day', x='is_part_time')\n",
    "plt.title('Average orders per day by shift length, FT=0, PT=1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize average pick time by individual operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "sns.scatterplot(data=operdf2, y='avg_sec_per_order', x='operator', hue='tenure_bin')\n",
    "plt.title('Average seconds per order by operator, color designates tenure')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "sns.scatterplot(data=operdf2, y='avg_sec_per_order', x='operator', hue='is_part_time')\n",
    "plt.title('Average seconds per order by operator, color designates FT=blue/PT=orange')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "sns.scatterplot(data=operdf2, y='avg_sec_per_order', x='operator', hue='avg_line_per_order')\n",
    "plt.title('Average seconds per order by operator, color designates avg_line_per_order')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd round Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd round preprocessing\n",
    "\n",
    "- want to add features based on the operator tenure and part time status\n",
    "- creating copy of X_train so don't overwrite current dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operdf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column in X train that looks up tenure bin value in operdf2 for the operator list\n",
    "# create column in X train that looks up is_part_time status of operator in operdf2\n",
    "\n",
    "# not sure what will happen if merge all columns, but only want tenure bin and is part time\n",
    "# create copy of operdf2 that has only operator tenure bin and is part time\n",
    "# https://www.geeksforgeeks.org/how-to-do-a-vlookup-in-python-using-pandas/\n",
    "\n",
    "oper_mergedf = operdf2[['tenure_bin', 'is_part_time']]\n",
    "oper_mergedf = oper_mergedf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oper_mergedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtraindf = pd.merge(train, oper_mergedf, on='operator', how='left')\n",
    "newtraindf\n",
    "# this will need to be preprocessed before modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create validate and test with new features\n",
    "newvaldf = pd.merge(validate, oper_mergedf, on='operator', how='left') \n",
    "newtestdf = pd.merge(test, oper_mergedf, on='operator', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtraindf[newtraindf.tenure_bin.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newvaldf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtestdf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after merge there are 236 out of 96K rows with null values in train\n",
    "# validate and test have 52 and 53 rows with null values\n",
    "# dropping these observations for modeling\n",
    "newtraindf = newtraindf.dropna()\n",
    "newvaldf = newvaldf.dropna()\n",
    "newtestdf = newtestdf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recheck for nulls\n",
    "newtraindf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to do X y split on new dataframes\n",
    "newX_train_exp, newX_train, newX_validate, newX_test, newy_train, newy_validate, newy_test = wrangle_pick.createXy(newtraindf, newvaldf, newtestdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess round 2 train, validate, test\n",
    "r2X_train, r2X_validate, r2X_test = wrangle_pick.model_preprocess2(newX_train, newX_validate, newX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2X_train.shape, r2X_validate.shape, r2X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Round Models\n",
    "\n",
    "Will use OSL and polynomial features (2 degrees) as before and continue using MAE (Median Absolute Error) for evaluation of the models.\n",
    "\n",
    "First evaluate using only tenure bin and is part time, follow up with only tenure bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_train_oper_features = r2X_train.drop(columns='total_lines_scaled')\n",
    "r2_val_oper_features = r2X_validate.drop(columns='total_lines_scaled')\n",
    "r2_test_oper_features = r2X_test.drop(columns='total_lines_scaled')\n",
    "r2_train_oper_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (OLS) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "r2lm = LinearRegression(normalize=True)\n",
    "# no change in result if normalize is True or False\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "r2lm.fit(r2_train_oper_features, newy_train.pick_seconds)\n",
    "\n",
    "# predict train\n",
    "newy_train['ps_pred_r2lm'] = r2lm.predict(r2_train_oper_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2lm_med_abs_train = median_absolute_error(newy_train.pick_seconds, newy_train.ps_pred_r2lm)\n",
    "print(\"MAE using Mean\\nTrain/In-Sample: \", round(r2lm_med_abs_train, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evsr2 = explained_variance_score(newy_train.pick_seconds, newy_train.ps_pred_r2lm)\n",
    "print('Explained Variance = ', round(evsr2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Feature Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "r2pf = PolynomialFeatures(degree=2)\n",
    "# fit and transform X_train_scaled\n",
    "r2X_train_degree = r2pf.fit_transform(r2_train_oper_features)\n",
    "# tried 3, 4, 8 degrees but not much different in performance and 2 is less likely to overfit\n",
    "    \n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "r2X_validate_degree = r2pf.transform(r2_val_oper_features)\n",
    "r2X_test_degree = r2pf.transform(r2_test_oper_features)\n",
    "\n",
    "# create the model object\n",
    "r2lmpf = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "r2lmpf.fit(r2X_train_degree, newy_train.pick_seconds)\n",
    "\n",
    "# predict train\n",
    "newy_train['ps_pred_r2pflm'] = r2lmpf.predict(r2X_train_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2pflm_med_abs_train = median_absolute_error(newy_train.pick_seconds, newy_train.ps_pred_r2pflm)\n",
    "print(\"MAE using Mean\\nTrain/In-Sample: \", round(r2pflm_med_abs_train, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Round Results Summary\n",
    "using only operator features is about equal to baseline\n",
    "\n",
    "No need for further validate or test due to poor performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd Round Models\n",
    "\n",
    "For this final set will use total line with operator features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2X_train.shape, r2X_validate.shape, r2X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (OLS) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "r3lm = LinearRegression(normalize=True)\n",
    "# no change in result if normalize is True or False\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "r3lm.fit(r2X_train, newy_train.pick_seconds)\n",
    "\n",
    "# predict train\n",
    "newy_train['ps_pred_r3lm'] = r3lm.predict(r2X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r3lm_med_abs_train = median_absolute_error(newy_train.pick_seconds, newy_train.ps_pred_r3lm)\n",
    "print(\"MAE using Mean\\nTrain/In-Sample: \", round(r3lm_med_abs_train, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Feature Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "r3pf = PolynomialFeatures(degree=2)\n",
    "# fit and transform X_train_scaled\n",
    "r3X_train_degree = r3pf.fit_transform(r2X_train)\n",
    "# tried 3, 4, 8 degrees but not much different in performance and 2 is less likely to overfit\n",
    "    \n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "r3X_validate_degree = r3pf.transform(r2X_validate)\n",
    "r3X_test_degree = r3pf.transform(r2X_test)\n",
    "\n",
    "# create the model object\n",
    "r3lmpf = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "r3lmpf.fit(r3X_train_degree, newy_train.pick_seconds)\n",
    "\n",
    "# predict train\n",
    "newy_train['ps_pred_r3pflm'] = r3lmpf.predict(r3X_train_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r3pflm_med_abs_train = median_absolute_error(newy_train.pick_seconds, newy_train.ps_pred_r3pflm)\n",
    "print(\"MAE using Mean\\nTrain/In-Sample: \", round(r3pflm_med_abs_train, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regreesion predict validate\n",
    "newy_validate['r3ps_pred_lm'] = r3lm.predict(r2X_validate)\n",
    "r3lm_med_abs_val = median_absolute_error(newy_validate.pick_seconds, newy_validate.r3ps_pred_lm)\n",
    "print(\"MAE using Mean\\nTrain/Out-of-Sample: \", round(r3lm_med_abs_val, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Features predict validate\n",
    "# predict validate\n",
    "newy_validate['r3ps_pred_pflm'] = r3lmpf.predict(r3X_validate_degree)\n",
    "r3pflm_med_abs_val = median_absolute_error(newy_validate.pick_seconds, newy_validate.r3ps_pred_pflm)\n",
    "print(\"MAE using Mean\\nTrain/Out-of-Sample: \", round(r3pflm_med_abs_val, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Features predict validate\n",
    "# predict test\n",
    "newy_test['r3ps_pred_pflm'] = r3lmpf.predict(r3X_test_degree)\n",
    "r3pflm_med_abs_test = median_absolute_error(newy_test.pick_seconds, newy_test.r3ps_pred_pflm)\n",
    "print(\"MAE using Mean\\nTrain/Out-of-Sample: \", round(r3pflm_med_abs_test, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evsr3 = explained_variance_score(newy_test.pick_seconds, newy_test.r3ps_pred_pflm)\n",
    "print('Explained Variance = ', round(evsr3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd Round Results Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAE (median absolute error) of the baseline (using just the mean pick seconds to predict) is 95 seconds     \n",
    "\n",
    "Using 3 features: total lines per order (a measure of order complexity), binned operator tenure, and part time status does not improve performance from using total lines alone.\n",
    "\n",
    "The minimal variation between performance of operators based on tenure time and/or FT/PT status in this dataset may be a factor. In a dataset with greater variation these factors might have more predictive impact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newy_validate['baseline_pred'] = bps_pred_mean\n",
    "newy_validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(newy_validate.pick_seconds, newy_validate.baseline_pred, alpha=.5, color=\"gray\", label='_nolegend_')\n",
    "plt.annotate(\"Baseline: Predict Using Mean\", (16, 9.5))\n",
    "plt.plot(newy_validate.pick_seconds, newy_validate.pick_seconds, alpha=.5, color=\"blue\", label='_nolegend_')\n",
    "plt.annotate(\"The Ideal Line: Predicted = Actual\", (.5, 3.5), rotation=25.5)\n",
    "\n",
    "plt.scatter(newy_validate.pick_seconds, newy_validate.r3ps_pred_lm, \n",
    "            alpha=.5, color=\"red\", s=100, label=\"Model: LinearRegression\")\n",
    "\n",
    "plt.scatter(newy_validate.pick_seconds, newy_validate.r3ps_pred_pflm, \n",
    "            alpha=.5, color=\"green\", s=100, label=\"Model 2nd degree Polynomial\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual pick seconds\")\n",
    "plt.ylabel(\"Predicted pick seconds\")\n",
    "plt.title(\"Where are predictions more extreme? More modest?\")\n",
    "# plt.annotate(\"The polynomial model appears to overreact to noise\", (2.0, -10))\n",
    "# plt.annotate(\"The OLS model (LinearRegression)\\n appears to be most consistent\", (15.5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.axhline(label=\"No Error\")\n",
    "plt.scatter(newy_validate.pick_seconds, newy_validate.r3ps_pred_pflm-newy_validate.pick_seconds, \n",
    "            alpha=.5, color=\"red\", s=100, label=\"Model: LinearRegression\")\n",
    "\n",
    "plt.scatter(newy_validate.pick_seconds, newy_validate.r3ps_pred_pflm-newy_validate.pick_seconds, \n",
    "            alpha=.5, color=\"green\", s=100, label=\"Model 2nd degree Polynomial\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual pick seconds\")\n",
    "plt.ylabel(\"Residual/Error: Predicted pick seconds - Actual pick seconds\")\n",
    "plt.title(\"Do the size of errors change as the actual value changes?\")\n",
    "#plt.annotate(\"The polynomial model appears to overreact to noise\", (2.0, -10))\n",
    "#plt.annotate(\"The OLS model (LinearRegression)\\n appears to be most consistent\", (15.5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pval = ols_model.f_pvalue\n",
    "\n",
    "print(\"p-value for model significance = \", round(f_pval,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.metrics.explained_variance_score\n",
    "\n",
    "evs = explained_variance_score(df.y, df.yhat)\n",
    "print('Explained Variance = ', round(evs,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "276px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
